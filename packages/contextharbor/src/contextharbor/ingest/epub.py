from __future__ import annotations

from dataclasses import dataclass
import json
from pathlib import Path
import time
from typing import Any, Optional

from bs4 import BeautifulSoup

from .. import config
from ..stores import ragstore
from ..services.evidence import heuristic_doc_genre


@dataclass(frozen=True)
class EpubInfo:
    path: str
    title: str
    authors: list[str]


@dataclass(frozen=True)
class EpubSection:
    label: str | None
    text: str


def _default_library_dir() -> Path:
    return Path(config.config.ebooks_dir)


def _extract_text_from_html(html: str) -> str:
    soup = BeautifulSoup(html or "", "lxml")
    for tag in soup(
        ["script", "style", "noscript", "svg", "header", "footer", "nav", "aside"]
    ):
        try:
            tag.decompose()
        except Exception:
            pass
    text = soup.get_text("\n")
    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
    return "\n".join(lines)


def _read_epub(
    epub_path: Path, *, root: Path | None = None
) -> tuple[EpubInfo, list[EpubSection]]:
    try:
        from ebooklib import epub, ITEM_DOCUMENT  # type: ignore
    except Exception as exc:  # pragma: no cover
        raise RuntimeError(
            "EPUB ingest requires the optional dependency 'ebooklib'. "
            "Install it with: python -m pip install ebooklib"
        ) from exc

    book = epub.read_epub(str(epub_path))

    title = ""
    authors: list[str] = []

    try:
        meta_title = book.get_metadata("DC", "title")
        if meta_title and isinstance(meta_title, list) and meta_title[0]:
            title = str(meta_title[0][0] or "").strip()
    except Exception:
        pass

    try:
        meta_auth = book.get_metadata("DC", "creator")
        if meta_auth and isinstance(meta_auth, list):
            for item in meta_auth:
                if not item:
                    continue
                a = str(item[0] or "").strip()
                if a:
                    authors.append(a)
    except Exception:
        pass

    sections: list[EpubSection] = []
    for idx, item in enumerate(book.get_items_of_type(ITEM_DOCUMENT), start=1):
        try:
            raw = item.get_content()
            html = (
                raw.decode("utf-8", errors="ignore")
                if isinstance(raw, (bytes, bytearray))
                else str(raw)
            )
            txt = _extract_text_from_html(html)
            if not txt:
                continue

            label = None
            try:
                name = getattr(item, "get_name", None)
                if callable(name):
                    label = str(name() or "").strip() or None
            except Exception:
                label = None
            if not label:
                label = f"section {idx}"

            sections.append(EpubSection(label=label, text=txt))
        except Exception:
            continue

    rel = str(epub_path)
    rel_root = root or _default_library_dir()
    try:
        rel = str(epub_path.relative_to(rel_root))
    except Exception:
        pass

    info = EpubInfo(
        path=rel,
        title=title or epub_path.stem,
        authors=authors,
    )
    return info, sections


def list_epubs(
    *, query: Optional[str] = None, limit: int = 25, library_dir: Optional[str] = None
) -> list[dict[str, Any]]:
    root = Path(library_dir) if library_dir else _default_library_dir()
    q = (query or "").strip().lower()
    limit = max(1, min(int(limit), 200))

    out: list[dict[str, Any]] = []
    if not root.exists() or not root.is_dir():
        return out

    paths: list[Path] = []
    for p in root.rglob("*.epub"):
        paths.append(p)
    paths.sort(key=lambda x: str(x).lower())

    for p in paths:
        if len(out) >= limit:
            break
        try:
            rel = str(p.relative_to(root))
        except Exception:
            rel = str(p)

        if q and q not in rel.lower():
            continue

        out.append({"path": rel})
    return out


def build_epub_index(*, library_dir: str) -> dict[str, Any]:
    """Build a static index of EPUB paths under a library directory."""

    root = Path(library_dir or "").expanduser().resolve()
    indexed_at = int(time.time())
    out: list[str] = []

    if not root.exists() or not root.is_dir():
        return {"library_dir": str(root), "indexed_at": indexed_at, "paths": out}

    for p in root.rglob("*.epub"):
        try:
            rel = str(p.relative_to(root))
        except Exception:
            rel = str(p)
        out.append(rel)
    out.sort(key=lambda s: s.lower())
    return {"library_dir": str(root), "indexed_at": indexed_at, "paths": out}


async def ingest_epub(
    *,
    path: str,
    embed_model: str | None = None,
    library_dir: Optional[str] = None,
) -> dict[str, Any]:
    root = (
        (Path(library_dir) if library_dir else _default_library_dir())
        .expanduser()
        .resolve()
    )
    p = Path(path or "")
    if p.is_absolute():
        try:
            _ = p.expanduser().resolve().relative_to(root)
        except Exception:
            return {
                "ok": False,
                "error": f"epub path must be under library_dir: {root}",
            }
        p = p.expanduser().resolve()
    else:
        p = (root / p).expanduser().resolve()
        try:
            _ = p.relative_to(root)
        except Exception:
            return {
                "ok": False,
                "error": f"epub path must be under library_dir: {root}",
            }

    if not p.exists() or not p.is_file():
        return {"ok": False, "error": f"epub not found: {p}"}

    # Compute the stable library-relative path used as the ingest identity.
    try:
        rel_path = str(p.relative_to(root))
    except Exception:
        rel_path = str(p)

    # Fast path: if this exact (source, path) is already ingested, don't re-embed.
    existing = ragstore.get_document_by_source_path("epub", rel_path)
    if existing:
        return {
            "ok": True,
            "already_ingested": True,
            "doc_id": int(existing.get("id") or 0),
            "title": existing.get("title") or p.stem,
            "authors": [
                a.strip()
                for a in str(existing.get("author") or "").split(",")
                if a.strip()
            ],
            "path": rel_path,
        }

    info, sections = _read_epub(p, root=root)
    if not sections:
        return {"ok": False, "error": "no extractable text"}

    filename = f"epub:{info.title}"
    if info.authors:
        filename = f"epub:{info.title} - {', '.join(info.authors)}"

    genre, _why = heuristic_doc_genre(
        title=info.title,
        author=", ".join(info.authors) if info.authors else None,
        path=info.path,
        tags=["epub"],
        default_genre=str(
            getattr(config.config, "epub_default_genre", "unknown") or "unknown"
        ),
    )
    tags = ["epub"]
    if genre in {"fiction", "nonfiction", "reference"}:
        tags.append(genre)

    meta_json = json.dumps(  # stored as string; keep it small
        {
            "source": "epub",
            "title": info.title,
            "authors": info.authors,
            "path": info.path,
            "genre": genre,
        },
        ensure_ascii=False,
    )

    doc_id = await ragstore.add_document_sections(
        filename,
        [(s.label, s.text) for s in sections],
        embed_model=embed_model,
        source="epub",
        title=info.title,
        author=", ".join(info.authors) if info.authors else None,
        path=info.path,
        meta_json=meta_json,
        group_name="epub",
        tags=tags,
    )

    return {
        "ok": True,
        "doc_id": doc_id,
        "title": info.title,
        "authors": info.authors,
        "path": info.path,
    }


async def ingest_epubs_by_query(
    *,
    query: str,
    limit: int = 3,
    embed_model: str | None = None,
    library_dir: Optional[str] = None,
) -> dict[str, Any]:
    q = (query or "").strip()
    if not q:
        return {"ok": False, "error": "query cannot be empty"}

    matches = list_epubs(query=q, limit=limit, library_dir=library_dir)
    results: list[dict[str, Any]] = []
    for m in matches:
        r = await ingest_epub(
            path=str(m.get("path") or ""),
            embed_model=embed_model,
            library_dir=library_dir,
        )
        results.append(r)
    return {"ok": True, "results": results, "count": len(results)}
